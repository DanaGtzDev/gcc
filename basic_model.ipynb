{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab4b8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93c2fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. GLOBAL ENCODERS & SCALERS ---\n",
    "le_marca = LabelEncoder()\n",
    "le_plant = LabelEncoder()\n",
    "feature_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d16f75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"consolidated_ordenes.csv\")\n",
    "df = df.drop(columns=[\"description\", \"main_plant\", \"changed_on\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8da312f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. GROUPING & PREPROCESSING\n",
    "# Assuming 'df' is your original DataFrame\n",
    "df = df.sort_values(by=['equipment', 'created_on'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc3736df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping into a list of DataFrames (The \"Pandas Way\")\n",
    "list_of_dfs = [group for name, group in df.groupby('equipment')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4177ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_rnn(list_of_dfs, window_size=10):\n",
    "    all_x, all_y = [], []\n",
    "    \n",
    "    # We use separate scalers: one for features, one for the target (days_diff)\n",
    "    # This makes it easier to \"un-scale\" your prediction later\n",
    "    target_scaler = MinMaxScaler()\n",
    "    \n",
    "    # Flattening for encoding purposes\n",
    "    full_df = pd.concat(list_of_dfs)\n",
    "    full_df['marca_enc'] = le_marca.fit_transform(full_df['marca'].astype(str))\n",
    "    full_df['plant_enc'] = le_plant.fit_transform(full_df['plant'].astype(str))\n",
    "    \n",
    "    # Re-split after encoding\n",
    "    processed_dfs = [group for name, group in full_df.groupby('equipment')]\n",
    "    \n",
    "    for sub_df in processed_dfs:\n",
    "        sub_df = sub_df.copy()\n",
    "        sub_df['created_on'] = pd.to_datetime(sub_df['created_on'])\n",
    "        \n",
    "        # Calculate days between orders (The \"Sequence\" logic)\n",
    "        sub_df['days_diff'] = sub_df['created_on'].diff().dt.days.fillna(0)\n",
    "        \n",
    "        # Select Features: [days_diff, modelo, marca_enc, plant_enc]\n",
    "        feature_cols = ['days_diff', 'modelo', 'marca_enc', 'plant_enc']\n",
    "        \n",
    "        if len(sub_df) <= window_size:\n",
    "            continue # Skip equipment with too little history\n",
    "            \n",
    "        # Scaling\n",
    "        scaled_features = feature_scaler.fit_transform(sub_df[feature_cols])\n",
    "        \n",
    "        # Sliding Window Generation\n",
    "        for i in range(len(scaled_features) - window_size):\n",
    "            # Input: The window of rows\n",
    "            all_x.append(scaled_features[i : i + window_size])\n",
    "            # Target: The 'days_diff' of the VERY NEXT row\n",
    "            all_y.append(scaled_features[i + window_size, 0]) \n",
    "            \n",
    "    return np.array(all_x), np.array(all_y), feature_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fb50ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GENERATE SEQUENCES\n",
    "WINDOW_SIZE = 40 # Looking at 12 orders to predict the 13th\n",
    "X, y, scaler = prepare_data_for_rnn(list_of_dfs, window_size=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8792954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Training (80%) and Testing (20%) sets\n",
    "# shuffle=True is okay here because our \"windows\" already contain the temporal order\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8abc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. BUILD THE RNN (LSTM) ---\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "    layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "    layers.LSTM(64, activation='tanh', return_sequences=False),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77b769cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d82b2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 19391 samples, validating on 4848 samples...\n",
      "Epoch 1/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0204 - mae: 0.0971 - val_loss: 0.0200 - val_mae: 0.0982\n",
      "Epoch 2/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0200 - mae: 0.0965 - val_loss: 0.0197 - val_mae: 0.0990\n",
      "Epoch 3/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0198 - mae: 0.0960 - val_loss: 0.0194 - val_mae: 0.0909\n",
      "Epoch 4/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0197 - mae: 0.0956 - val_loss: 0.0192 - val_mae: 0.0927\n",
      "Epoch 5/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0197 - mae: 0.0956 - val_loss: 0.0192 - val_mae: 0.0940\n",
      "Epoch 6/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0196 - mae: 0.0956 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 7/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0196 - mae: 0.0954 - val_loss: 0.0192 - val_mae: 0.0931\n",
      "Epoch 8/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - loss: 0.0196 - mae: 0.0954 - val_loss: 0.0192 - val_mae: 0.0962\n",
      "Epoch 9/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0196 - mae: 0.0955 - val_loss: 0.0192 - val_mae: 0.0947\n",
      "Epoch 10/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0196 - mae: 0.0955 - val_loss: 0.0193 - val_mae: 0.0952\n",
      "Epoch 11/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0953 - val_loss: 0.0193 - val_mae: 0.0952\n",
      "Epoch 12/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0195 - mae: 0.0952 - val_loss: 0.0194 - val_mae: 0.0956\n",
      "Epoch 13/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0954 - val_loss: 0.0192 - val_mae: 0.0923\n",
      "Epoch 14/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0952 - val_loss: 0.0192 - val_mae: 0.0922\n",
      "Epoch 15/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0194 - mae: 0.0951 - val_loss: 0.0192 - val_mae: 0.0942\n",
      "Epoch 16/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0951 - val_loss: 0.0193 - val_mae: 0.0915\n",
      "Epoch 17/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0952 - val_loss: 0.0193 - val_mae: 0.0926\n",
      "Epoch 18/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0950 - val_loss: 0.0194 - val_mae: 0.0955\n",
      "Epoch 19/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0950 - val_loss: 0.0194 - val_mae: 0.0948\n",
      "Epoch 20/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 0.0194 - mae: 0.0950 - val_loss: 0.0192 - val_mae: 0.0936\n",
      "Epoch 21/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0195 - mae: 0.0950 - val_loss: 0.0193 - val_mae: 0.0943\n",
      "Epoch 22/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0195 - mae: 0.0950 - val_loss: 0.0193 - val_mae: 0.0939\n",
      "Epoch 23/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.0195 - mae: 0.0951 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 24/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 0.0194 - mae: 0.0948 - val_loss: 0.0194 - val_mae: 0.0972\n",
      "Epoch 25/25\n",
      "\u001b[1m1212/1212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - loss: 0.0194 - mae: 0.0949 - val_loss: 0.0193 - val_mae: 0.0917\n"
     ]
    }
   ],
   "source": [
    "# --- 4. TRAIN ---\n",
    "print(f\"Training on {X_train.shape[0]} samples, validating on {X_test.shape[0]} samples...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=25, \n",
    "    batch_size=16, \n",
    "    validation_data=(X_test, y_test), # Use the test set for validation during training\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97437e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n"
     ]
    }
   ],
   "source": [
    "# --- NEW: EVALUATION ---\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a0cb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 0.0193\n",
      "Test Mean Absolute Error (Scaled): 0.0917\n",
      "Average Prediction Error: 2.57 days\n"
     ]
    }
   ],
   "source": [
    "# To understand the MAE in real days, we must reverse the scaling\n",
    "# Since days_diff was the first column (index 0) in our scaler:\n",
    "days_range = scaler.data_range_[0]\n",
    "real_mae = mae * days_range\n",
    "\n",
    "print(f\"Test Loss (MSE): {loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error (Scaled): {mae:.4f}\")\n",
    "print(f\"Average Prediction Error: {real_mae:.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "308a9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_order(equipment_df, model, scaler, window_size, le_marca, le_plant):\n",
    "    # 1. Create a copy to avoid modifying your original data\n",
    "    sample = equipment_df.copy()\n",
    "    \n",
    "    # 2. Feature Engineering: Dates to Deltas\n",
    "    sample['created_on'] = pd.to_datetime(sample['created_on'])\n",
    "    sample = sample.sort_values('created_on')\n",
    "    sample['days_diff'] = sample['created_on'].diff().dt.days.fillna(0)\n",
    "    \n",
    "    # 3. Categorical Encoding\n",
    "    # We use 'transform' (not fit_transform) to use the training labels\n",
    "    sample['marca_enc'] = le_marca.transform(sample['marca'].astype(str))\n",
    "    sample['plant_enc'] = le_plant.transform(sample['plant'].astype(str))\n",
    "    \n",
    "    # 4. Select only the columns the model was trained on\n",
    "    feature_cols = ['days_diff', 'modelo', 'marca_enc', 'plant_enc']\n",
    "    recent_history = sample[feature_cols].tail(window_size)\n",
    "    \n",
    "    if len(recent_history) < window_size:\n",
    "        return f\"Error: Equipment only has {len(recent_history)} orders. Need {window_size}.\"\n",
    "\n",
    "    # 5. Scale and Reshape\n",
    "    scaled_input = scaler.transform(recent_history)\n",
    "    scaled_input = scaled_input.reshape(1, window_size, len(feature_cols))\n",
    "    \n",
    "    # 6. Predict and Inverse Scale\n",
    "    prediction_scaled = model.predict(scaled_input, verbose=0)\n",
    "    \n",
    "    # To un-scale, we create a dummy array matching the scaler's width\n",
    "    dummy = np.zeros((1, len(feature_cols)))\n",
    "    dummy[0, 0] = prediction_scaled[0][0]\n",
    "    prediction_final = scaler.inverse_transform(dummy)[0, 0]\n",
    "    \n",
    "    return max(0, prediction_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2bcbc39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average order frequency: 12.95 days\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate days_diff for every row within its own equipment group\n",
    "# This ensures we don't calculate the gap between \"Equipment A\" and \"Equipment B\"\n",
    "df['created_on'] = pd.to_datetime(df['created_on'])\n",
    "df = df.sort_values(['equipment', 'created_on'])\n",
    "\n",
    "# Group by equipment and calculate the difference between orders\n",
    "df['days_diff'] = df.groupby('equipment')['created_on'].diff().dt.days\n",
    "\n",
    "# 2. Get the mean for each equipment\n",
    "avg_per_equipment = df.groupby('equipment')['days_diff'].mean()\n",
    "\n",
    "# 3. Get the final global average\n",
    "final_avg = avg_per_equipment.mean()\n",
    "\n",
    "print(f\"Global average order frequency: {final_avg:.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e201bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next order in: 3.3 days\n"
     ]
    }
   ],
   "source": [
    "days_to_next = predict_next_order(list_of_dfs[21], model, scaler, WINDOW_SIZE, le_marca, le_plant)\n",
    "print(f\"Predicted next order in: {days_to_next:.1f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fdbe4c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: basic_model_directory/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: basic_model_directory/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'basic_model_directory'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40, 4), dtype=tf.float32, name='keras_tensor_40')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140399196633808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196633232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196632464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196632272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196632848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140398728809936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196632080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196631120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196630544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196632656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399196633616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399208462288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140399208463440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"basic_model_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9bf4762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le_plant.pkl']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scalers and encoders\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "joblib.dump(le_marca, 'le_marca.pkl')\n",
    "joblib.dump(le_plant, 'le_plant.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
